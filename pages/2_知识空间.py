"""
çŸ¥è¯†ç©ºé—´é¡µé¢
æ˜¾ç¤ºå’Œç®¡ç†çŸ¥è¯†ç©ºé—´ä¸­çš„æ–‡æ¡£å†…å®¹
"""
import streamlit as st
import sys
import os
import pandas as pd
from pathlib import Path
from typing import List, Dict

# å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ°Pythonè·¯å¾„ä¸­
from src.utils import setup_project_path
setup_project_path()

from config.load_key import load_config

# è‡ªå®šä¹‰CSS
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');
    
    .stApp {
        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
        font-family: 'Inter', sans-serif;
    }
    
    .main .block-container {
        padding-top: 2rem;
        padding-bottom: 2rem;
        max-width: 1600px;
    }
    
    /* æ–‡æ¡£å¡ç‰‡æ ·å¼ */
    .doc-card {
        background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%);
        border-radius: 16px;
        padding: 1.5rem;
        margin-bottom: 1rem;
        box-shadow: 0 4px 16px rgba(0, 0, 0, 0.1);
        border-left: 4px solid #667eea;
        transition: all 0.3s ease;
    }
    
    .doc-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 8px 24px rgba(0, 0, 0, 0.15);
    }
    
    /* æ–‡æ¡£å†…å®¹æ¡†æ ·å¼ */
    .doc-content-box {
        background: linear-gradient(135deg, #f0f4ff 0%, #e0e7ff 100%);
        padding: 1.25rem;
        border-radius: 12px;
        border-left: 4px solid #667eea;
        margin-bottom: 1rem;
        box-shadow: 0 2px 8px rgba(102, 126, 234, 0.1);
    }
    
    /* æŒ‰é’®æ ·å¼ä¼˜åŒ– */
    .stButton > button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 12px;
        padding: 0.5rem 1.5rem;
        font-weight: 500;
        transition: all 0.3s ease;
        box-shadow: 0 4px 12px rgba(102, 126, 234, 0.3);
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(102, 126, 234, 0.4);
    }
    
    /* ä¾§è¾¹æ æ ·å¼ */
    [data-testid="stSidebar"] {
        background: linear-gradient(180deg, #ffffff 0%, #f8f9fa 100%);
    }
    
    /* ä¿¡æ¯æ¡†æ ·å¼ */
    .stInfo {
        background: linear-gradient(135deg, #e0f2fe 0%, #bae6fd 100%);
        border-left: 4px solid #0ea5e9;
        border-radius: 8px;
    }
    
    /* è¡¨æ ¼æ ·å¼ä¼˜åŒ– */
    .stDataFrame {
        border-radius: 12px;
        overflow: hidden;
    }
    
    /* ç»Ÿè®¡æŒ‡æ ‡æ ·å¼ */
    [data-testid="stMetricValue"] {
        font-size: 1.5rem;
        font-weight: 600;
    }
    
    /* æœç´¢æ¡†æ ·å¼ */
    .stTextInput > div > div > input {
        border-radius: 12px;
        border: 2px solid #e1e8ed;
        padding: 0.75rem 1rem;
        transition: all 0.3s ease;
    }
    
    .stTextInput > div > div > input:focus {
        border-color: #667eea;
        box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.1);
    }
</style>
""", unsafe_allow_html=True)

def load_knowledge_space() -> List[Dict[str, str]]:
    """
    åŠ è½½çŸ¥è¯†ç©ºé—´ä¸­çš„æ‰€æœ‰æ–‡æ¡£
    
    Returns:
        List[Dict]: æ–‡æ¡£åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«file_name, content, file_path
    """
    config = load_config()
    rag_config = config.get("rag", {})
    knowledge_space_dir = rag_config.get("knowledge_space_dir", "./rag_source/knowledge_space")
    
    documents = []
    if not os.path.exists(knowledge_space_dir):
        return documents
    
    # éå†ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
    for file_name in os.listdir(knowledge_space_dir):
        file_path = os.path.join(knowledge_space_dir, file_name)
        if os.path.isfile(file_path) and (file_name.endswith('.txt') or file_name.endswith('.md')):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                documents.append({
                    'file_name': file_name,
                    'content': content,
                    'file_path': file_path,
                    'file_size': len(content),
                    'word_count': len(content)
                })
            except Exception as e:
                st.warning(f"è¯»å–æ–‡ä»¶ {file_name} æ—¶å‡ºé”™: {e}")
    
    return documents

# é¡µé¢æ ‡é¢˜
st.markdown("""
<div style='text-align: center; margin-bottom: 2rem;'>
    <h1 style='margin: 0; color: #2c3e50; font-size: 2.5rem;'>ğŸ“š çŸ¥è¯†ç©ºé—´</h1>
    <p style='margin: 0.5rem 0 0 0; color: #5a6c7d; font-size: 1.1rem;'>æŸ¥çœ‹å’Œç®¡ç†çŸ¥è¯†ç©ºé—´ä¸­çš„æ–‡æ¡£å†…å®¹</p>
</div>
""", unsafe_allow_html=True)

# é¡µé¢åŠŸèƒ½è¯´æ˜
st.info("""
**ğŸ“‹ åŠŸèƒ½è¯´æ˜ï¼š** ç®¡ç†çŸ¥è¯†ç©ºé—´ä¸­çš„æ–‡æ¡£ï¼Œè¿™äº›æ–‡æ¡£å°†ç”¨äºRAGæ£€ç´¢ã€‚æ”¯æŒæŸ¥çœ‹æ–‡æ¡£å†…å®¹ã€æœç´¢å…³é”®è¯ã€ç»Ÿè®¡æ–‡æ¡£ä¿¡æ¯ç­‰åŠŸèƒ½ã€‚
""")

# åŠ è½½æ•°æ®
@st.cache_data(ttl=5)  # 5ç§’ç¼“å­˜ï¼Œç¡®ä¿æ•°æ®å®æ—¶æ›´æ–°
def load_cached_knowledge_space():
    return load_knowledge_space()

all_documents = load_cached_knowledge_space()

# ä¾§è¾¹æ  - ç»Ÿè®¡ä¿¡æ¯
with st.sidebar:
    st.markdown("### ğŸ“Š ç»Ÿè®¡ä¿¡æ¯")
    
    if all_documents:
        total_docs = len(all_documents)
        total_words = sum(doc['word_count'] for doc in all_documents)
        avg_words = total_words / total_docs if total_docs > 0 else 0
        total_size = sum(doc['file_size'] for doc in all_documents)
        
        st.metric("æ–‡æ¡£æ€»æ•°", total_docs)
        st.metric("æ€»å­—æ•°", f"{total_words:,}")
        st.metric("å¹³å‡å­—æ•°", f"{avg_words:.0f}")
        st.metric("æ€»å¤§å°", f"{total_size / 1024:.2f} KB")
    else:
        st.metric("æ–‡æ¡£æ€»æ•°", 0)
        st.metric("æ€»å­—æ•°", 0)
    
    st.markdown("---")
    
    # æ“ä½œæŒ‰é’®
    st.markdown("### ğŸ› ï¸ æ“ä½œ")
    if st.button("ğŸ”„ åˆ·æ–°æ•°æ®", use_container_width=True):
        # æ¸…é™¤ç¼“å­˜
        st.cache_data.clear()
        st.rerun()
    
    # è‡ªåŠ¨åˆ·æ–°æç¤º
    st.caption("ğŸ’¡ æ•°æ®æ¯5ç§’è‡ªåŠ¨æ›´æ–°ï¼Œæˆ–ç‚¹å‡»åˆ·æ–°æŒ‰é’®ç«‹å³æ›´æ–°")

# ä¸»è¦å†…å®¹åŒºåŸŸ
if not all_documents:
    st.info("ğŸ“­ çŸ¥è¯†ç©ºé—´ä¸­æš‚æ— æ–‡æ¡£ã€‚è¯·å°†æ–‡æ¡£æ–‡ä»¶ï¼ˆ.txt æˆ– .md æ ¼å¼ï¼‰æ”¾å…¥ `rag_source/knowledge_space/` ç›®å½•ã€‚")
else:
    # æœç´¢åŠŸèƒ½
    search_query = st.text_input("ğŸ” æœç´¢æ–‡æ¡£", placeholder="è¾“å…¥å…³é”®è¯æœç´¢æ–‡æ¡£åç§°æˆ–å†…å®¹...", help="åœ¨æ–‡æ¡£åç§°å’Œå†…å®¹ä¸­æœç´¢å…³é”®è¯")
    
    # ç­›é€‰æ•°æ®ï¼ˆæ’é™¤ç©ºæ–‡æ¡£ï¼‰
    filtered_documents = [doc for doc in all_documents if doc['content'].strip()]
    if search_query:
        search_lower = search_query.lower()
        filtered_documents = [
            doc for doc in filtered_documents
            if search_lower in doc['file_name'].lower() or search_lower in doc['content'].lower()
        ]
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("æ€»æ–‡æ¡£æ•°", len(all_documents))
    with col2:
        st.metric("å½“å‰æ˜¾ç¤º", len(filtered_documents))
    with col3:
        total_words_display = sum(doc['word_count'] for doc in filtered_documents)
        st.metric("æ€»å­—æ•°", f"{total_words_display:,}")
    with col4:
        avg_words_display = total_words_display / len(filtered_documents) if filtered_documents else 0
        st.metric("å¹³å‡å­—æ•°", f"{avg_words_display:.0f}")
    
    st.markdown("---")
    
    # è¡¨æ ¼å±•ç¤º
    st.markdown("### ğŸ“‹ æ–‡æ¡£åˆ—è¡¨")
    
    if not filtered_documents:
        st.warning("æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„æ–‡æ¡£ã€‚è¯·è°ƒæ•´æœç´¢å…³é”®è¯ã€‚")
    else:
        # å‡†å¤‡è¡¨æ ¼æ•°æ®
        table_data = []
        for idx, doc in enumerate(filtered_documents, 1):
            # æˆªæ–­é•¿æ–‡æœ¬ï¼ˆç”¨äºè¡¨æ ¼æ˜¾ç¤ºï¼Œå®Œæ•´å†…å®¹å­˜å‚¨åœ¨å®Œæ•´å­—æ®µä¸­ï¼‰
            # ç§»é™¤ç©ºè¡Œå’Œå¤šä½™ç©ºç™½ï¼Œå°†å†…å®¹å‹ç¼©ä¸ºå•è¡Œé¢„è§ˆ
            content_clean = doc['content'].strip()
            # ç§»é™¤æ‰€æœ‰æ¢è¡Œç¬¦å’Œå¤šä½™ç©ºæ ¼ï¼Œå‹ç¼©ä¸ºå•è¡Œ
            content_clean = ' '.join([line.strip() for line in content_clean.split('\n') if line.strip()])
            content_short = content_clean[:150] + "..." if len(content_clean) > 150 else content_clean
            
            table_data.append({
                "åºå·": idx,
                "æ–‡ä»¶å": doc['file_name'],
                "å†…å®¹é¢„è§ˆ": content_short,
                "å­—æ•°": doc['word_count'],
                "å¤§å°": f"{doc['file_size'] / 1024:.2f} KB",
                "å®Œæ•´å†…å®¹": doc['content']
            })
        
        # åˆ›å»ºDataFrame
        df = pd.DataFrame(table_data)
        
        # é€‰æ‹©è¦æ˜¾ç¤ºçš„åˆ—
        display_columns = ["åºå·", "æ–‡ä»¶å", "å†…å®¹é¢„è§ˆ", "å­—æ•°", "å¤§å°"]
        df_display = df[display_columns].copy()
        
        # ä¸ºæ¯è¡Œæ·»åŠ æç¤ºï¼ˆå¦‚æœå†…å®¹è¢«æˆªæ–­ï¼‰
        for idx, row in df_display.iterrows():
            full_content = df.loc[idx, "å®Œæ•´å†…å®¹"]
            if len(full_content) > 150:
                df_display.at[idx, "å†…å®¹é¢„è§ˆ"] = f"{row['å†…å®¹é¢„è§ˆ']} (ç‚¹å‡»æŸ¥çœ‹è¯¦æƒ…)"
        
        # ä½¿ç”¨st.dataframeå±•ç¤ºè¡¨æ ¼
        selected_rows = st.dataframe(
            df_display,
            use_container_width=True,
            height=600,
            hide_index=True,
            column_config={
                "åºå·": st.column_config.NumberColumn("åºå·", width="small"),
                "æ–‡ä»¶å": st.column_config.TextColumn("æ–‡ä»¶å", width="medium"),
                "å†…å®¹é¢„è§ˆ": st.column_config.TextColumn(
                    "å†…å®¹é¢„è§ˆ", 
                    width="large",
                    help="å†…å®¹è¾ƒé•¿æ—¶è¯·ç‚¹å‡»ä¸‹æ–¹'è¯¦ç»†ä¿¡æ¯æŸ¥çœ‹'æŸ¥çœ‹å®Œæ•´å†…å®¹"
                ),
                "å­—æ•°": st.column_config.NumberColumn("å­—æ•°", width="small"),
                "å¤§å°": st.column_config.TextColumn("å¤§å°", width="small"),
            }
        )
        
        st.markdown("---")
        
        # è¯¦ç»†ä¿¡æ¯æŸ¥çœ‹åŒºåŸŸ
        st.markdown("### ğŸ” è¯¦ç»†ä¿¡æ¯æŸ¥çœ‹")
        
        # é€‰æ‹©è¦æŸ¥çœ‹çš„æ–‡æ¡£
        doc_options = [f"{idx+1}. {doc['file_name']}" for idx, doc in enumerate(filtered_documents)]
        
        if doc_options:
            selected_idx = st.selectbox(
                "é€‰æ‹©æ–‡æ¡£æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯",
                range(len(doc_options)),
                format_func=lambda x: doc_options[x],
                index=0
            )
            
            selected_doc = filtered_documents[selected_idx]
            
            # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
            col1, col2 = st.columns([3, 1])
            
            with col1:
                st.markdown("#### ğŸ“ åŸºæœ¬ä¿¡æ¯")
                info_data = {
                    "æ–‡ä»¶å": selected_doc['file_name'],
                    "å­—æ•°": f"{selected_doc['word_count']:,} å­—",
                    "æ–‡ä»¶å¤§å°": f"{selected_doc['file_size'] / 1024:.2f} KB",
                    "æ–‡ä»¶è·¯å¾„": selected_doc['file_path']
                }
                for key, value in info_data.items():
                    st.markdown(f"**{key}**: {value}")
            
            with col2:
                st.markdown("#### ğŸ“Š ç»Ÿè®¡")
                st.metric("å­—æ•°", selected_doc['word_count'])
                st.metric("å¤§å°", f"{selected_doc['file_size'] / 1024:.2f} KB")
            
            st.markdown("---")
            
            # æ–‡æ¡£å†…å®¹ï¼ˆé»˜è®¤æ”¶èµ·ï¼‰
            with st.expander("ğŸ“„ æŸ¥çœ‹æ–‡æ¡£å†…å®¹", expanded=False):
                # ä½¿ç”¨st.markdownç›´æ¥æ¸²æŸ“Markdownå†…å®¹
                st.markdown(selected_doc['content'])

