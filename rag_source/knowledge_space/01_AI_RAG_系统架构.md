# AI RAG 系统架构文档

## 系统概述

AI RAG Pro 是一个基于检索增强生成（Retrieval-Augmented Generation, RAG）技术的智能问答系统。该系统通过结合知识库检索和大语言模型生成，为用户提供准确、可靠的问答服务。

## 核心组件

### 1. 知识空间（Knowledge Space）

知识空间是系统的核心知识存储区域，包含结构化和非结构化的文档资料。这些文档经过向量化处理后存储在向量数据库中，支持高效的语义检索。

**特点：**
- 支持多种文档格式（TXT、MD、PDF等）
- 自动向量化和索引
- 支持增量更新
- 持久化存储

### 2. 意图空间（Intent Space）

意图空间存储高质量的问答对，用于快速响应常见问题。当用户提问时，系统首先在意图空间中检索相似问题，如果相似度足够高，直接返回标准答案。

**特点：**
- 快速响应常见问题
- 答案质量高、标准化
- 支持动态更新
- 从反馈空间中提取优质问答对

### 3. 反馈空间（Feedback Space）

反馈空间收集用户对问答结果的反馈，包括评分、改进建议等。这些反馈数据用于：
- 持续优化系统回答质量
- 识别高频问题
- 提取优质问答对到意图空间
- 分析用户需求和系统改进方向

## 技术架构

### 向量数据库

系统使用 ChromaDB 作为向量数据库，存储文档的嵌入向量。每个文档被分割成多个chunk，每个chunk生成对应的向量表示。

### 嵌入模型

系统支持多种嵌入模型：
- DashScope Text Embedding V2（默认）
- BGE-large-zh-v1.5
- 其他兼容的嵌入模型

### 大语言模型

系统支持多种LLM：
- DeepSeek API（优先）
- DashScope Qwen系列
- OpenAI GPT系列

### RAG流程

1. **问题理解**：系统首先理解用户问题的语义
2. **意图检索**：在意图空间中检索相似问题
3. **知识检索**：如果意图空间没有匹配，在知识空间中检索相关文档
4. **答案生成**：基于检索到的信息，使用LLM生成答案
5. **反馈收集**：收集用户反馈，用于持续优化

## 数据流

```
用户问题 → 意图空间检索 → [匹配] → 返回标准答案
                ↓ [未匹配]
          知识空间检索 → 文档片段 → LLM生成 → 返回答案
                ↓
          用户反馈 → 反馈空间 → 数据分析 → 系统优化
```

## 优势

1. **准确性高**：基于知识库检索，确保答案有据可依
2. **响应快速**：意图空间提供快速响应通道
3. **持续优化**：反馈机制支持系统自我改进
4. **可扩展性强**：支持多种文档格式和模型
5. **灵活配置**：支持自定义提示词和参数调整

## 应用场景

- 企业内部知识库问答
- 产品文档智能查询
- 技术支持系统
- 教育培训平台
- 专业领域知识问答

