import streamlit as st
import sys
import os
import logging
from pathlib import Path

# å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ°Pythonè·¯å¾„ä¸­
from src.utils import setup_project_path
setup_project_path()

from src.retriever import RAGManager
from src.feedback import FeedbackStore
from src.general_assistant import handle_general_assistant
from src.industry_assistant import handle_industry_assistant
from src.evaluation import calculate_metrics, format_metrics_display
from config.load_key import load_key
from src.llm import get_llm_service
from é¦–é¡µ import load_rag_manager, get_rag_manager_cache_key

# åŠ è½½é…ç½®æ–‡ä»¶ä¸­çš„APIå¯†é’¥åˆ°ç¯å¢ƒå˜é‡
from config.load_key import load_key
load_key()

# è‡ªå®šä¹‰CSSï¼Œç¾åŒ–ç•Œé¢
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');
    
    .stApp {
        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
        font-family: 'Inter', sans-serif;
    }
    
    .main .block-container {
        padding-top: 2rem;
        padding-bottom: 2rem;
        max-width: 1200px;
    }
    
    /* èŠå¤©å®¹å™¨æ ·å¼ */
    .stChatInputContainer {
        background: white;
        border-radius: 15px;
        box-shadow: 0 4px 20px rgba(0, 0, 0, 0.1);
        border: 1px solid #e1e8ed;
    }
    
    .stChatInputContainer > div {
        background: white;
        border-radius: 15px;
    }
    
    /* ç”¨æˆ·æ¶ˆæ¯æ ·å¼ */
    [data-testid="stChatMessageContent"][data-testid*="user"] {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-radius: 18px 18px 5px 18px;
        padding: 1rem 1.25rem;
        margin: 0.5rem 0;
        box-shadow: 0 4px 12px rgba(102, 126, 234, 0.3);
        border: none;
    }
    
    /* AIåŠ©æ‰‹æ¶ˆæ¯æ ·å¼ */
    [data-testid="stChatMessageContent"]:not([data-testid*="user"]) {
        background: linear-gradient(145deg, #ffffff 0%, #f8f9fa 100%);
        border: 1px solid #e1e8ed;
        border-radius: 18px 18px 18px 5px;
        padding: 1rem 1.25rem;
        margin: 0.5rem 0;
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.08);
        position: relative;
    }
    
    /* æŒ‰é’®æ ·å¼ */
    .stButton > button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 12px;
        padding: 0.5rem 1.5rem;
        font-weight: 500;
        transition: all 0.3s ease;
        box-shadow: 0 4px 12px rgba(102, 126, 234, 0.3);
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(102, 126, 234, 0.4);
    }
    
    /* ä¾§è¾¹æ æ ·å¼ */
    [data-testid="stSidebar"] {
        background: linear-gradient(180deg, #ffffff 0%, #f8f9fa 100%);
    }
    
    /* åŠ è½½åŠ¨ç”» */
    .stSpinner {
        text-align: center;
    }
    
    /* å±•å¼€å™¨æ ·å¼ */
    .streamlit-expanderHeader {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-radius: 12px;
        font-weight: 500;
        padding: 0.75rem 1rem;
        transition: all 0.3s ease;
    }
    
    .streamlit-expanderHeader:hover {
        box-shadow: 0 4px 12px rgba(102, 126, 234, 0.3);
    }
    
    /* èŠå¤©åŒºåŸŸå®¹å™¨ */
    .chat-container {
        background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%);
        border-radius: 16px;
        padding: 2rem;
        margin: 1rem 0;
        box-shadow: 0 8px 24px rgba(0, 0, 0, 0.12);
        border: 1px solid rgba(255, 255, 255, 0.8);
        transition: all 0.3s ease;
    }
    
    .chat-container:hover {
        box-shadow: 0 12px 32px rgba(0, 0, 0, 0.15);
    }
    
    /* çŠ¶æ€æŒ‡ç¤ºå™¨ */
    .status-indicator {
        display: inline-flex;
        align-items: center;
        gap: 0.5rem;
        padding: 0.5rem 1rem;
        background: #e8f5e8;
        border-radius: 20px;
        font-size: 0.85rem;
        color: #2e7d32;
        margin-bottom: 1rem;
    }
    
    /* æ€è€ƒå†…å®¹æ ·å¼ */
    .streamlit-expanderContent {
        background: linear-gradient(135deg, #f0f4ff 0%, #e0e7ff 100%);
        border-radius: 12px;
        padding: 1.25rem;
        border-left: 4px solid #667eea;
        box-shadow: 0 2px 8px rgba(102, 126, 234, 0.1);
        margin-top: 0.5rem;
    }
    
    /* ä¾§è¾¹æ æ ‡é¢˜æ ·å¼ */
    .sidebar-title {
        text-align: center;
        padding: 1.25rem;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        border-radius: 12px;
        margin-bottom: 1rem;
        color: white;
        box-shadow: 0 4px 12px rgba(102, 126, 234, 0.3);
    }
    
    .sidebar-title h2 {
        margin: 0;
        font-size: 1.5rem;
        color: white;
    }
    
    /* è¡¨å•å…ƒç´ æ ·å¼ */
    .stRadio > div {
        background: white;
        border-radius: 12px;
        padding: 0.5rem;
    }
    
    .stSelectbox > div > div > select {
        border-radius: 12px;
        border: 2px solid #e1e8ed;
        padding: 0.5rem;
        transition: all 0.3s ease;
    }
    
    .stSelectbox > div > div > select:focus {
        border-color: #667eea;
        box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.1);
    }
    
    .stSlider > div > div {
        border-radius: 12px;
    }
    
    .stCheckbox > label {
        font-weight: 500;
    }
    
    /* çŠ¶æ€æŒ‡ç¤ºå™¨ä¼˜åŒ– */
    .status-indicator {
        display: inline-flex;
        align-items: center;
        gap: 0.5rem;
        padding: 0.5rem 1rem;
        background: linear-gradient(135deg, #f0fdf4 0%, #dcfce7 100%);
        border-radius: 12px;
        font-size: 0.85rem;
        color: #10b981;
        margin-bottom: 1rem;
        box-shadow: 0 2px 8px rgba(16, 185, 129, 0.1);
        border-left: 4px solid #10b981;
    }
    
    /* ä¿¡æ¯æ¡†æ ·å¼ */
    .stInfo {
        background: linear-gradient(135deg, #e0f2fe 0%, #bae6fd 100%);
        border-left: 4px solid #0ea5e9;
        border-radius: 8px;
    }
    
    /* æˆåŠŸæ¶ˆæ¯æ ·å¼ */
    .stSuccess {
        background: linear-gradient(135deg, #f0fdf4 0%, #dcfce7 100%);
        border-left: 4px solid #10b981;
        border-radius: 8px;
    }
    
    /* é”™è¯¯æ¶ˆæ¯æ ·å¼ */
    .stError {
        background: linear-gradient(135deg, #fef2f2 0%, #fee2e2 100%);
        border-left: 4px solid #ef4444;
        border-radius: 8px;
    }
    
    /* è­¦å‘Šæ¶ˆæ¯æ ·å¼ */
    .stWarning {
        background: linear-gradient(135deg, #fef3c7 0%, #fde68a 100%);
        border-left: 4px solid #f59e0b;
        border-radius: 8px;
    }
</style>
""", unsafe_allow_html=True)

# åˆå§‹åŒ–åé¦ˆå­˜å‚¨å®ä¾‹
feedback_store = FeedbackStore()

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.markdown("""
    <div class='sidebar-title'>
        <h2>ğŸ¤– AI RAG Pro</h2>
        <p style='margin: 0.5rem 0 0 0; opacity: 0.9; font-size: 0.9rem;'>æ™ºèƒ½é—®ç­”ç³»ç»Ÿ</p>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("### âš™ï¸ ç³»ç»Ÿé…ç½®")
    
    # æ£€æŸ¥ RAG ä¾èµ–æ˜¯å¦å¯ç”¨
    rag_available = False
    rag_error_msg = ""
    try:
        import llama_index
        from llama_index.embeddings.dashscope import DashScopeEmbedding
        from config.load_key import get_api_key
        if get_api_key("DASHSCOPE_API_KEY"):
            rag_available = True
        else:
            rag_error_msg = "æœªé…ç½® DashScope API Key"
    except ImportError as e:
        rag_error_msg = f"ç¼ºå°‘ä¾èµ–: {str(e)}"
    except Exception as e:
        rag_error_msg = f"æ£€æŸ¥å¤±è´¥: {str(e)}"
    
    qa_mode = st.radio(
        "åŠ©æ‰‹æ¨¡å¼", 
        ["é€šç”¨åŠ©æ‰‹", "è¡Œä¸šåŠ©æ‰‹"], 
        index=0,
        help="é€šç”¨åŠ©æ‰‹ï¼šç›´æ¥ä½¿ç”¨å¤§æ¨¡å‹å›ç­”ï¼›è¡Œä¸šåŠ©æ‰‹ï¼šä»çŸ¥è¯†ç©ºé—´ã€æ„å›¾ç©ºé—´å’Œåé¦ˆç©ºé—´ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯åå›ç­”",
        horizontal=True
    )
    rag_enabled = (qa_mode == "è¡Œä¸šåŠ©æ‰‹")
    
    # å¦‚æœé€‰æ‹©äº†è¡Œä¸šåŠ©æ‰‹ä½†ä¾èµ–ä¸å¯ç”¨ï¼Œæ˜¾ç¤ºè­¦å‘Š
    if rag_enabled and not rag_available:
        st.warning(f"âš ï¸ è¡Œä¸šåŠ©æ‰‹å½“å‰ä¸å¯ç”¨: {rag_error_msg}")
        st.info("""
        **è§£å†³æ–¹æ¡ˆï¼š**
        1. ç¡®ä¿å·²æ¿€æ´»æ­£ç¡®çš„ conda ç¯å¢ƒï¼ˆå¦‚ `llamaindex_310`ï¼‰
        2. å®‰è£…ä¾èµ–ï¼š`pip install llama-index llama-index-embeddings-dashscope`
        3. æ£€æŸ¥ `config/config.json` ä¸­çš„ DashScope API Key é…ç½®
        4. é‡å¯ Streamlit åº”ç”¨
        """)
    
    # æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹é€‰é¡¹
    show_thinking = st.checkbox("ğŸ’­ æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹", value=False, help="å¼€å¯åï¼Œæ¨¡å‹ä¼šå±•ç¤ºå…¶æ€è€ƒæ¨ç†è¿‡ç¨‹")
    
    # RAGæ£€ç´¢å‚æ•°ï¼ˆä»…åœ¨RAGæ¨¡å¼ä¸‹æ˜¾ç¤ºï¼‰
    if rag_enabled:
        st.markdown("---")
        st.markdown("### ğŸ“Š RAGæ£€ç´¢å‚æ•°")
        k_knowledge = st.slider("çŸ¥è¯†ç©ºé—´TopK", min_value=1, max_value=10, value=3, help="ä»çŸ¥è¯†ç©ºé—´æ£€ç´¢çš„æ–‡æ¡£æ•°é‡")
        k_intent = st.slider("æ„å›¾ç©ºé—´TopK", min_value=1, max_value=5, value=1, help="ä»æ„å›¾ç©ºé—´æ£€ç´¢çš„é—®ç­”å¯¹æ•°é‡")
        intent_threshold = st.slider("æ„å›¾ç›´è¿”é˜ˆå€¼", min_value=0.5, max_value=0.99, value=0.85, step=0.01, 
                                     help="æ„å›¾ç©ºé—´ç›¸ä¼¼åº¦è¶…è¿‡æ­¤å€¼æ—¶ç›´æ¥è¿”å›ç­”æ¡ˆï¼Œå¦åˆ™ç»§ç»­æŸ¥è¯¢çŸ¥è¯†ç©ºé—´")
    else:
        # é€šç”¨é—®ç­”æ¨¡å¼ä¸‹è®¾ç½®é»˜è®¤å€¼ï¼ˆè™½ç„¶ä¸ä¼šä½¿ç”¨ï¼‰
        k_knowledge = 3
        k_intent = 1
        intent_threshold = 0.85
    
    st.markdown("---")
    st.markdown("### ğŸ› ï¸ ç®¡ç†åŠŸèƒ½")
    col1, col2, col3 = st.columns(3)
    with col1:
        clear_chat = st.button("ğŸ—‘ï¸ æ¸…ç©ºä¼šè¯", use_container_width=True)
    with col2:
        export_chat = st.button("ğŸ“¥ å¯¼å‡ºå¯¹è¯", use_container_width=True)
    with col3:
        clear_cache = st.button("ğŸ”„ æ¸…é™¤ç¼“å­˜", use_container_width=True, help="æ¸…é™¤ RAG ç®¡ç†å™¨ç¼“å­˜ï¼Œå¼ºåˆ¶é‡æ–°åŠ è½½é…ç½®")
    
    st.markdown("---")
    
    # ä½¿ç”¨æç¤º
    st.markdown("""
    <div style='background: #e8f4fd; padding: 1rem; border-radius: 8px; border-left: 4px solid #2196F3;'>
        <h4 style='margin: 0 0 0.5rem 0; color: #1976D2;'>ğŸ’¡ ä½¿ç”¨æç¤º</h4>
        <ul style='margin: 0; padding-left: 1rem; font-size: 0.85rem; color: #424242;'>
            <li>é€‰æ‹©é€‚åˆçš„åŠ©æ‰‹æ¨¡å¼ï¼ˆé€šç”¨åŠ©æ‰‹æˆ–è¡Œä¸šåŠ©æ‰‹ï¼‰</li>
            <li>è¯¦ç»†æè¿°æ‚¨çš„é—®é¢˜</li>
            <li>è¡Œä¸šåŠ©æ‰‹ä¼šä»çŸ¥è¯†ç©ºé—´ã€æ„å›¾ç©ºé—´æ£€ç´¢ä¿¡æ¯</li>
            <li>å¯ä»¥è°ƒæ•´æ£€ç´¢å‚æ•°ä¼˜åŒ–å›ç­”è´¨é‡</li>
            <li>åé¦ˆæœ‰åŠ©äºç³»ç»Ÿæ”¹è¿›</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)

# å¤„ç†ä¾§è¾¹æ æ“ä½œ
if clear_chat:
    st.session_state.messages = []
    st.rerun()

if clear_cache:
    load_rag_manager.clear()
    st.success("âœ… ç¼“å­˜å·²æ¸…é™¤ï¼ŒRAG ç®¡ç†å™¨å°†é‡æ–°åŠ è½½")
    st.rerun()

if export_chat:
    import json
    chat_data = json.dumps(st.session_state.get("messages", []), ensure_ascii=False, indent=2)
    st.sidebar.download_button(
        "ğŸ“¥ ä¸‹è½½JSON", 
        data=chat_data, 
        file_name=f"chat_{st.session_state.get('session_id', 'export')}.json",
        mime="application/json"
    )


# --- è·å–å½“å‰ä½¿ç”¨çš„LLMæä¾›å•† ---
llm_provider_name = ""
try:
    if rag_enabled:
        # è¡Œä¸šåŠ©æ‰‹æ¨¡å¼
        cache_key = get_rag_manager_cache_key()
        rag_manager = load_rag_manager(_cache_key=cache_key)
        if rag_manager and hasattr(rag_manager, 'llm_provider') and rag_manager.llm_provider:
            llm_provider_name = rag_manager.llm_provider
    else:
        # é€šç”¨åŠ©æ‰‹æ¨¡å¼
        llm_service = get_llm_service()
        if llm_service and hasattr(llm_service, 'provider') and llm_service.provider:
            llm_provider_name = llm_service.provider
except Exception as e:
    logging.warning(f"æ— æ³•è·å–LLMæä¾›å•†åç§°: {e}")

# ä¸»è¦å†…å®¹åŒºåŸŸ
# æ ¹æ®åŠ©æ‰‹æ¨¡å¼åŠ¨æ€æ˜¾ç¤ºæè¿°
subtitle_base = "åŸºäºçŸ¥è¯†åº“çš„æ™ºèƒ½é—®ç­”åŠ©æ‰‹" if rag_enabled else "é€šç”¨æ™ºèƒ½é—®ç­”åŠ©æ‰‹"
subtitle_text = f"{subtitle_base} (æ¨¡å‹: {llm_provider_name})" if llm_provider_name else subtitle_base

st.markdown(f"""
<div class='chat-container'>
    <div style='text-align: center; margin-bottom: 1.5rem;'>
        <h1 style='margin: 0; color: #2c3e50; font-size: 2.2rem;'>ğŸ¤– AI RAG Pro é—®ç­”ç³»ç»Ÿ</h1>
        <p style='margin: 0.5rem 0 0 0; color: #5a6c7d; font-size: 1rem;'>{subtitle_text}</p>
    </div>
</div>
""", unsafe_allow_html=True)

# çŠ¶æ€æŒ‡ç¤ºå™¨
status_color = "#e8f5e8" if rag_enabled else "#fff3cd"
status_text_color = "#2e7d32" if rag_enabled else "#856404"
mode_display = "ğŸ” è¡Œä¸šåŠ©æ‰‹" if rag_enabled else "ğŸ¤– é€šç”¨åŠ©æ‰‹"

st.markdown(f"""
<div style='display: flex; justify-content: center; margin-bottom: 1rem;'>
    <div style='display: inline-flex; align-items: center; gap: 0.5rem; padding: 0.5rem 1rem; 
                background: {status_color}; border-radius: 20px; font-size: 0.85rem; color: {status_text_color};'>
        <span>{mode_display}</span>
    </div>
</div>
""", unsafe_allow_html=True)

# --- åˆå§‹åŒ–èŠå¤©ä¼šè¯ ---
if "messages" not in st.session_state:
    st.session_state.messages = [
        {
            "role": "assistant", 
            "content": "æ‚¨å¥½ï¼æˆ‘æ˜¯ AI RAG Pro æ™ºèƒ½é—®ç­”åŠ©æ‰‹ ğŸ¤–\n\næˆ‘å¯ä»¥ä¸ºæ‚¨æä¾›ä¸¤ç§åŠ©æ‰‹æ¨¡å¼ï¼š\n\n1. **é€šç”¨åŠ©æ‰‹**ï¼šç›´æ¥ä½¿ç”¨å¤§æ¨¡å‹è¿›è¡Œå›ç­”ï¼Œé€‚åˆä¸€èˆ¬æ€§é—®é¢˜\n2. **è¡Œä¸šåŠ©æ‰‹**ï¼šä»çŸ¥è¯†ç©ºé—´ã€æ„å›¾ç©ºé—´å’Œåé¦ˆç©ºé—´ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯åå›ç­”ï¼Œé€‚åˆéœ€è¦ä¸“ä¸šçŸ¥è¯†çš„é—®é¢˜\n\nğŸ’¡ æç¤ºï¼šæ‚¨å¯ä»¥åœ¨ä¾§è¾¹æ é€‰æ‹©åŠ©æ‰‹æ¨¡å¼ï¼Œè°ƒæ•´æ£€ç´¢å‚æ•°æ¥ä¼˜åŒ–å›ç­”è´¨é‡ï¼Œä¹Ÿå¯ä»¥å¯¹å›ç­”è¿›è¡Œåé¦ˆä»¥å¸®åŠ©ç³»ç»Ÿæ”¹è¿›ã€‚"
        }
    ]

# --- æ˜¾ç¤ºå†å²æ¶ˆæ¯ ---
for idx, message in enumerate(st.session_state.messages):
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        
        # ä¸ºåŠ©æ‰‹æ¶ˆæ¯æ˜¾ç¤ºåé¦ˆåŠŸèƒ½
        if message["role"] == "assistant" and idx > 0:  # è·³è¿‡æ¬¢è¿æ¶ˆæ¯
            # åˆå§‹åŒ–è¯¥æ¶ˆæ¯çš„åé¦ˆçŠ¶æ€
            feedback_key = f"feedback_{idx}"
            if feedback_key not in st.session_state:
                st.session_state[feedback_key] = {
                    "fb_choice": "ğŸ‘ æœ‰å¸®åŠ©",
                    "stars": 4,
                    "tags": [],
                    "correction": "",
                    "submitted": False
                }
            
            # å¦‚æœå·²ç»æäº¤è¿‡ï¼Œæ˜¾ç¤ºå·²æäº¤çŠ¶æ€
            if st.session_state[feedback_key]["submitted"]:
                st.info("âœ… åé¦ˆå·²æäº¤ï¼Œæ„Ÿè°¢æ‚¨çš„åé¦ˆï¼")
            else:
                # æ˜¾ç¤ºåé¦ˆåŠŸèƒ½
                with st.expander("ğŸ’¬ åé¦ˆ", expanded=False):
                    fb_choice = st.radio(
                        "æ˜¯å¦æœ‰å¸®åŠ©", 
                        ["ğŸ‘ æœ‰å¸®åŠ©", "ğŸ‘ æ— å¸®åŠ©"], 
                        horizontal=True,
                        key=f"fb_choice_{idx}",
                        index=0 if st.session_state[feedback_key]["fb_choice"] == "ğŸ‘ æœ‰å¸®åŠ©" else 1
                    )
                    # æ£€æŸ¥é€‰æ‹©æ˜¯å¦æ”¹å˜ï¼Œå¦‚æœæ”¹å˜åˆ™è‡ªåŠ¨è°ƒæ•´è¯„åˆ†
                    old_choice = st.session_state[feedback_key]["fb_choice"]
                    st.session_state[feedback_key]["fb_choice"] = fb_choice
                    
                    # å¦‚æœé€‰æ‹©æ”¹å˜äº†ï¼Œè‡ªåŠ¨è°ƒæ•´è¯„åˆ†
                    if old_choice != fb_choice:
                        st.session_state[feedback_key]["stars"] = 4 if fb_choice.startswith("ğŸ‘") else 2
                    
                    # æ˜Ÿæ˜Ÿè¯„åˆ†ç»„ä»¶
                    st.markdown("**è¯„åˆ†**")
                    stars = st.session_state[feedback_key]["stars"]
                    cols = st.columns(6)
                    for i in range(6):  # 0-5åˆ†ï¼Œå…±6ä¸ªé€‰é¡¹
                        with cols[i]:
                            label = f"{i}åˆ†" if i == 0 else f"{i}â­"
                            if st.button(
                                label,
                                key=f"star_{i}_{idx}",
                                use_container_width=True,
                                type="primary" if stars == i else "secondary"
                            ):
                                st.session_state[feedback_key]["stars"] = i
                                st.rerun()
                    stars = st.session_state[feedback_key]["stars"]
                    # æ˜¾ç¤ºå½“å‰è¯„åˆ†
                    if stars > 0:
                        st.markdown(f"å½“å‰è¯„åˆ†ï¼š{'â­' * stars} ({stars}/5)")
                    else:
                        st.markdown("å½“å‰è¯„åˆ†ï¼šâšª (0/5)")
                    
                    tags = st.multiselect(
                        "é—®é¢˜ç±»å‹", 
                        ["äº‹å®é”™è¯¯", "ä¸æ¸…æ™°", "è¿‡æ—¶", "ä¸ç›¸å…³", "å…¶ä»–"], 
                        default=st.session_state[feedback_key]["tags"],
                        key=f"tags_{idx}"
                    )
                    st.session_state[feedback_key]["tags"] = tags
                    
                    correction = st.text_area(
                        "æ”¹è¿›ç­”æ¡ˆï¼ˆå¯é€‰ï¼‰", 
                        value=st.session_state[feedback_key]["correction"], 
                        height=100,
                        key=f"correction_{idx}"
                    )
                    st.session_state[feedback_key]["correction"] = correction
                    
                    if st.button("æäº¤åé¦ˆ", use_container_width=True, key=f"submit_feedback_{idx}"):
                        rating = stars  # ä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„è¯„åˆ†ï¼ˆ0-5ï¼‰
                        # è·å–å¯¹åº”çš„ç”¨æˆ·é—®é¢˜
                        user_question = st.session_state.messages[idx - 1]["content"] if idx > 0 else ""
                        assistant_answer = message["content"]
                        
                        # æ›´æ–°å·²å­˜åœ¨çš„äº¤äº’è®°å½•çš„åé¦ˆä¿¡æ¯
                        interaction_id = st.session_state[feedback_key].get("interaction_id")
                        if interaction_id:
                            # æ›´æ–°å·²å­˜åœ¨çš„è®°å½•
                            sources_payload = {
                                "tags": tags, 
                                "source_nodes": []
                            }
                            feedback_store.update_interaction_feedback(interaction_id, rating, correction)
                        else:
                            # å¦‚æœæ²¡æœ‰interaction_idï¼Œåˆ›å»ºæ–°è®°å½•ï¼ˆå…¼å®¹æ—§é€»è¾‘ï¼‰
                            sources_payload = {
                                "tags": tags, 
                                "source_nodes": []
                            }
                            feedback_store.add_interaction(user_question, assistant_answer, str(sources_payload), rating, correction)
                        
                        # æ ‡è®°ä¸ºå·²æäº¤
                        st.session_state[feedback_key]["submitted"] = True
                        
                        # æ¸…é™¤ç›¸å…³é¡µé¢çš„ç¼“å­˜ï¼Œç¡®ä¿æ•°æ®å®æ—¶æ›´æ–°
                        # æ¸…é™¤åé¦ˆç©ºé—´å’Œæ„å›¾ç©ºé—´çš„ç¼“å­˜
                        st.cache_data.clear()
                        
                        # å¦‚æœæœ‰æ­£é¢åé¦ˆå’Œæ”¹è¿›å»ºè®®ï¼Œæ›´æ–°æ„å›¾ç´¢å¼•
                        if rating >= 4 and len(correction.strip()) > 0:
                            try:
                                cache_key = get_rag_manager_cache_key()
                                rag_manager = load_rag_manager(_cache_key=cache_key)
                                if rag_manager:
                                    rag_manager.refresh_intent_index()
                                    st.info("ğŸ”„ æ„å›¾ç´¢å¼•å·²æ›´æ–°")
                            except Exception as e:
                                st.warning(f"âš ï¸ æ›´æ–°æ„å›¾ç´¢å¼•æ—¶å‡ºé”™: {e}")
                        
                        st.rerun()  # åˆ·æ–°é¡µé¢ä»¥æ˜¾ç¤ºå·²æäº¤çŠ¶æ€

# --- æ¥æ”¶ç”¨æˆ·è¾“å…¥å¹¶ç”Ÿæˆå“åº” ---
if prompt := st.chat_input("è¯·åœ¨è¿™é‡Œè¾“å…¥æ‚¨çš„é—®é¢˜..."):
    # å°†ç”¨æˆ·æ¶ˆæ¯æ·»åŠ åˆ°èŠå¤©è®°å½•
    st.session_state.messages.append({"role": "user", "content": prompt})
    # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    with st.chat_message("user"):
        st.markdown(prompt)

    # æ˜¾ç¤ºæ€è€ƒä¸­çš„æç¤º
    with st.chat_message("assistant"):
        # åˆå§‹åŒ–å˜é‡ï¼Œç¡®ä¿åœ¨æ‰€æœ‰ä»£ç è·¯å¾„ä¸­éƒ½æœ‰å®šä¹‰
        thinking_content_final = ""  # ç”¨äºå­˜å‚¨æœ€ç»ˆçš„æ€è€ƒè¿‡ç¨‹å†…å®¹
        full_response = ""  # ç”¨äºå­˜å‚¨æœ€ç»ˆçš„å›ç­”å†…å®¹
        thinking_placeholder = None
        src_nodes = []  # æºèŠ‚ç‚¹åˆ—è¡¨
        sources_str = ""  # æ¥æºå­—ç¬¦ä¸²
        used_intent_space = False  # æ˜¯å¦ä½¿ç”¨æ„å›¾ç©ºé—´
        intent_score = 0.0  # æ„å›¾ç©ºé—´ç›¸ä¼¼åº¦åˆ†æ•°
        if show_thinking:
            thinking_placeholder = st.empty()
            thinking_placeholder.markdown("ğŸ’­ **æ€è€ƒè¿‡ç¨‹ï¼š**\n\n*æ­£åœ¨åˆ†æé—®é¢˜...*")
        message_placeholder = st.empty()
        message_placeholder.markdown("æ­£åœ¨æ€è€ƒä¸­...")

        try:
            if rag_enabled:
                # è¡Œä¸šåŠ©æ‰‹æ¨¡å¼ï¼šå‚è€ƒçŸ¥è¯†ç©ºé—´ã€æ„å›¾ç©ºé—´å’Œåé¦ˆç©ºé—´
                try:
                    cache_key = get_rag_manager_cache_key()
                    rag_manager = load_rag_manager(_cache_key=cache_key)
                    if rag_manager is not None:
                        try:
                            full_response, src_nodes, sources_str, used_intent_space, intent_score = handle_industry_assistant(
                                rag_manager=rag_manager,
                                prompt=prompt,
                                message_placeholder=message_placeholder,
                                thinking_placeholder=thinking_placeholder,
                                k_intent=k_intent,
                                k_knowledge=k_knowledge,
                                intent_threshold=intent_threshold,
                                show_thinking=show_thinking
                            )
                            st.session_state.messages.append({"role": "assistant", "content": full_response})
                        except Exception as e:
                            logging.error(f"è¡Œä¸šåŠ©æ‰‹å¤„ç†å¤±è´¥: {e}", exc_info=True)
                            error_msg = f"âŒ è¡Œä¸šåŠ©æ‰‹å¤„ç†å¤±è´¥: {str(e)}"
                            st.error(error_msg)
                            full_response = f"æŠ±æ­‰ï¼Œå¤„ç†é—®é¢˜æ—¶å‡ºç°é”™è¯¯: {str(e)}"
                            message_placeholder.markdown(full_response)
                            st.session_state.messages.append({"role": "assistant", "content": full_response})
                            src_nodes = []
                            sources_str = ""
                            used_intent_space = False
                            intent_score = 0.0
                    else:
                        full_response = "æŠ±æ­‰ï¼Œç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•æˆ–ä½¿ç”¨é€šç”¨åŠ©æ‰‹æ¨¡å¼ã€‚"
                        message_placeholder.markdown(full_response)
                        st.session_state.messages.append({"role": "assistant", "content": full_response})
                        src_nodes = []
                        sources_str = ""
                        used_intent_space = False
                        intent_score = 0.0
                except ImportError as e:
                    # ä¾èµ–ç¼ºå¤±é”™è¯¯
                    error_msg = f"""
                    **âŒ ç¼ºå°‘å¿…è¦çš„ä¾èµ–åŒ…**
                    
                    **é”™è¯¯ä¿¡æ¯ï¼š** {str(e)}
                    
                    **è§£å†³æ–¹æ¡ˆï¼š**
                    1. æ¿€æ´»æ­£ç¡®çš„ conda ç¯å¢ƒï¼š
                       ```bash
                       conda activate llamaindex_310
                       ```
                    2. å®‰è£…ä¾èµ–ï¼š
                       ```bash
                       pip install llama-index llama-index-embeddings-dashscope
                       ```
                    3. é‡å¯ Streamlit åº”ç”¨ï¼š
                       ```bash
                       python -m streamlit run é¦–é¡µ.py
                       ```
                    """
                    logging.error(f"ä¾èµ–ç¼ºå¤±: {e}", exc_info=True)
                    st.error(error_msg)
                    full_response = "âš ï¸ ç¼ºå°‘å¿…è¦çš„ä¾èµ–åŒ…ï¼Œè¯·æŒ‰ç…§æç¤ºå®‰è£…åé‡å¯åº”ç”¨ã€‚"
                    message_placeholder.markdown(full_response)
                    st.session_state.messages.append({"role": "assistant", "content": full_response})
                    src_nodes = []
                    sources_str = ""
                    used_intent_space = False
                    intent_score = 0.0
                except Exception as e:
                    logging.error(f"åŠ è½½RAGç®¡ç†å™¨å¤±è´¥: {e}", exc_info=True)
                    error_msg = f"âŒ åŠ è½½RAGç®¡ç†å™¨å¤±è´¥: {str(e)}"
                    st.error(error_msg)
                    full_response = f"æŠ±æ­‰ï¼Œç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {str(e)}ã€‚è¯·ç¨åé‡è¯•æˆ–ä½¿ç”¨é€šç”¨åŠ©æ‰‹æ¨¡å¼ã€‚"
                    message_placeholder.markdown(full_response)
                    st.session_state.messages.append({"role": "assistant", "content": full_response})
                    src_nodes = []
                    sources_str = ""
                    used_intent_space = False
                    intent_score = 0.0
            else:
                # é€šç”¨åŠ©æ‰‹æ¨¡å¼ï¼šç›´æ¥è°ƒç”¨LLMï¼Œä¸ä½¿ç”¨RAG
                full_response, src_nodes, sources_str = handle_general_assistant(
                    prompt=prompt,
                    message_placeholder=message_placeholder,
                    thinking_placeholder=thinking_placeholder,
                    show_thinking=show_thinking
                )
                st.session_state.messages.append({"role": "assistant", "content": full_response})
                used_intent_space = False
                intent_score = 0.0
            
            # è‡ªåŠ¨è®°å½•é—®ç­”äº¤äº’ï¼ˆæ— åé¦ˆï¼‰ï¼Œç”¨äºç»Ÿè®¡é«˜é¢‘é—®é¢˜
            sources_payload = {
                "source_nodes": src_nodes and [getattr(n.node, "metadata", {}) for n in src_nodes] or []
            }
            interaction_id = feedback_store.add_interaction_without_feedback(
                prompt, 
                full_response, 
                str(sources_payload)
            )
            # å°†interaction_idå­˜å‚¨åˆ°session_stateï¼Œä»¥ä¾¿åç»­æ›´æ–°åé¦ˆ
            current_msg_idx = len(st.session_state.messages) - 1
            feedback_key = f"feedback_{current_msg_idx}"
            if feedback_key not in st.session_state:
                st.session_state[feedback_key] = {
                    "fb_choice": "ğŸ‘ æœ‰å¸®åŠ©",
                    "stars": 4,
                    "tags": [],
                    "correction": "",
                    "submitted": False,
                    "interaction_id": interaction_id  # å­˜å‚¨äº¤äº’ID
                }
            else:
                st.session_state[feedback_key]["interaction_id"] = interaction_id
            
            # è®¡ç®—å¹¶æ˜¾ç¤ºè¯„ä¼°æŒ‡æ ‡
            metrics = calculate_metrics(
                answer=full_response,
                src_nodes=src_nodes,
                used_intent_space=used_intent_space,
                intent_score=intent_score
            )
            
            # æ˜¾ç¤ºè¯„ä¼°æŒ‡æ ‡ï¼ˆç´§å‡‘ç‰ˆï¼‰
            with st.expander("ğŸ“Š è¯„ä¼°æŒ‡æ ‡", expanded=False):
                if rag_enabled:
                    # è¡Œä¸šåŠ©æ‰‹æ¨¡å¼ï¼šç´§å‡‘å¸ƒå±€
                    # ç¬¬ä¸€è¡Œï¼šåŸºç¡€æŒ‡æ ‡
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("æ£€ç´¢æ–‡æ¡£æ•°", metrics.retrieval_count)
                    with col2:
                        st.metric("å›ç­”é•¿åº¦", f"{metrics.answer_length} å­—ç¬¦")
                    with col3:
                        if metrics.max_similarity_score > 0:
                            st.metric("æœ€é«˜ç›¸ä¼¼åº¦", f"{metrics.max_similarity_score:.3f}")
                        else:
                            st.metric("æœ€é«˜ç›¸ä¼¼åº¦", "N/A")
                    with col4:
                        st.metric("æ„å›¾åŒ¹é…", "âœ…" if metrics.used_intent_space else "âŒ")
                    
                    # ç¬¬äºŒè¡Œï¼šè¯„ä¼°æŒ‡æ ‡ï¼ˆç½®ä¿¡åº¦ã€ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1ï¼‰
                    eval_col1, eval_col2, eval_col3, eval_col4 = st.columns(4)
                    with eval_col1:
                        st.metric("ç½®ä¿¡åº¦", f"{metrics.confidence:.3f}")
                    with eval_col2:
                        st.metric("ç²¾ç¡®ç‡", f"{metrics.precision:.3f}")
                    with eval_col3:
                        st.metric("å¬å›ç‡", f"{metrics.recall:.3f}")
                    with eval_col4:
                        st.metric("F1åˆ†æ•°", f"{metrics.f1_score:.3f}")
                else:
                    # é€šç”¨åŠ©æ‰‹æ¨¡å¼ï¼šç´§å‡‘å¸ƒå±€
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("å›ç­”é•¿åº¦", f"{metrics.answer_length} å­—ç¬¦")
                    with col2:
                        st.metric("å›ç­”è¯æ•°", f"{metrics.answer_word_count} è¯")
                    with col3:
                        st.metric("ç½®ä¿¡åº¦", f"{metrics.confidence:.3f}" if metrics.confidence > 0 else "N/A")
                    with col4:
                        st.caption("ğŸ’¡ é€šç”¨åŠ©æ‰‹æ¨¡å¼ä¸ä½¿ç”¨RAGæ£€ç´¢")
            
            # æ˜¾ç¤ºæ¥æºä¿¡æ¯
            if rag_enabled and src_nodes:
                with st.expander("ğŸ“š æ¥æºä¸è¯„åˆ†", expanded=False):
                    for i, n in enumerate(src_nodes[:3], 1):  # åªæ˜¾ç¤ºå‰3ä¸ª
                        md = getattr(n.node, "metadata", {})
                        sc = getattr(n, "score", None)
                        st.markdown(f"**æ¥æº {i}**")
                        st.json({"metadata": md, "ç›¸ä¼¼åº¦åˆ†æ•°": sc})
            
            # åé¦ˆåŠŸèƒ½ - ä¸ºæ–°ç”Ÿæˆçš„å›ç­”åˆ›å»ºåé¦ˆ
            # è·å–å½“å‰æ¶ˆæ¯çš„ç´¢å¼•ï¼ˆå·²åœ¨ä¸Šé¢å®šä¹‰ï¼‰
            
            # å¦‚æœå·²ç»æäº¤è¿‡ï¼Œæ˜¾ç¤ºå·²æäº¤çŠ¶æ€
            if st.session_state[feedback_key]["submitted"]:
                st.info("âœ… åé¦ˆå·²æäº¤ï¼Œæ„Ÿè°¢æ‚¨çš„åé¦ˆï¼")
            else:
                # æ˜¾ç¤ºåé¦ˆåŠŸèƒ½
                with st.expander("ğŸ’¬ åé¦ˆ", expanded=False):
                    fb_choice = st.radio(
                        "æ˜¯å¦æœ‰å¸®åŠ©", 
                        ["ğŸ‘ æœ‰å¸®åŠ©", "ğŸ‘ æ— å¸®åŠ©"], 
                        horizontal=True,
                        key=f"fb_choice_{current_msg_idx}",
                        index=0 if st.session_state[feedback_key]["fb_choice"] == "ğŸ‘ æœ‰å¸®åŠ©" else 1
                    )
                    # æ£€æŸ¥é€‰æ‹©æ˜¯å¦æ”¹å˜ï¼Œå¦‚æœæ”¹å˜åˆ™è‡ªåŠ¨è°ƒæ•´è¯„åˆ†
                    old_choice = st.session_state[feedback_key]["fb_choice"]
                    st.session_state[feedback_key]["fb_choice"] = fb_choice
                    
                    # å¦‚æœé€‰æ‹©æ”¹å˜äº†ï¼Œè‡ªåŠ¨è°ƒæ•´è¯„åˆ†
                    if old_choice != fb_choice:
                        st.session_state[feedback_key]["stars"] = 4 if fb_choice.startswith("ğŸ‘") else 2
                    
                    # æ˜Ÿæ˜Ÿè¯„åˆ†ç»„ä»¶
                    st.markdown("**è¯„åˆ†**")
                    stars = st.session_state[feedback_key]["stars"]
                    cols = st.columns(6)
                    for i in range(6):  # 0-5åˆ†ï¼Œå…±6ä¸ªé€‰é¡¹
                        with cols[i]:
                            star_text = "â­" * i if i > 0 else "âšª"
                            label = f"{i}åˆ†" if i == 0 else f"{i}â­"
                            if st.button(
                                label,
                                key=f"star_{i}_{current_msg_idx}",
                                use_container_width=True,
                                type="primary" if stars == i else "secondary"
                            ):
                                st.session_state[feedback_key]["stars"] = i
                                st.rerun()
                    stars = st.session_state[feedback_key]["stars"]
                    # æ˜¾ç¤ºå½“å‰è¯„åˆ†
                    if stars > 0:
                        st.markdown(f"å½“å‰è¯„åˆ†ï¼š{'â­' * stars} ({stars}/5)")
                    else:
                        st.markdown("å½“å‰è¯„åˆ†ï¼šâšª (0/5)")
                    
                    tags = st.multiselect(
                        "é—®é¢˜ç±»å‹", 
                        ["äº‹å®é”™è¯¯", "ä¸æ¸…æ™°", "è¿‡æ—¶", "ä¸ç›¸å…³", "å…¶ä»–"], 
                        default=st.session_state[feedback_key]["tags"],
                        key=f"tags_{current_msg_idx}"
                    )
                    st.session_state[feedback_key]["tags"] = tags
                    
                    correction = st.text_area(
                        "æ”¹è¿›ç­”æ¡ˆï¼ˆå¯é€‰ï¼‰", 
                        value=st.session_state[feedback_key]["correction"], 
                        height=100,
                        key=f"correction_{current_msg_idx}"
                    )
                    st.session_state[feedback_key]["correction"] = correction
                    
                    if st.button("æäº¤åé¦ˆ", use_container_width=True, key=f"submit_feedback_{current_msg_idx}"):
                        rating = stars  # ä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„è¯„åˆ†ï¼ˆ0-5ï¼‰
                        # æ›´æ–°å·²å­˜åœ¨çš„äº¤äº’è®°å½•çš„åé¦ˆä¿¡æ¯
                        interaction_id = st.session_state[feedback_key].get("interaction_id")
                        if interaction_id:
                            # æ›´æ–°å·²å­˜åœ¨çš„è®°å½•
                            sources_payload = {
                                "tags": tags, 
                                "source_nodes": src_nodes and [getattr(n.node, "metadata", {}) for n in src_nodes] or []
                            }
                            # æ›´æ–°sourceså­—æ®µä»¥åŒ…å«tags
                            feedback_store.update_interaction_feedback(interaction_id, rating, correction)
                        else:
                            # å¦‚æœæ²¡æœ‰interaction_idï¼Œåˆ›å»ºæ–°è®°å½•ï¼ˆå…¼å®¹æ—§é€»è¾‘ï¼‰
                            sources_payload = {
                                "tags": tags, 
                                "source_nodes": src_nodes and [getattr(n.node, "metadata", {}) for n in src_nodes] or []
                            }
                            feedback_store.add_interaction(prompt, full_response, str(sources_payload), rating, correction)
                        
                        # æ ‡è®°ä¸ºå·²æäº¤
                        st.session_state[feedback_key]["submitted"] = True
                        
                        # æ¸…é™¤ç›¸å…³é¡µé¢çš„ç¼“å­˜ï¼Œç¡®ä¿æ•°æ®å®æ—¶æ›´æ–°
                        # æ¸…é™¤åé¦ˆç©ºé—´å’Œæ„å›¾ç©ºé—´çš„ç¼“å­˜
                        st.cache_data.clear()
                        
                        # å¦‚æœæœ‰æ­£é¢åé¦ˆå’Œæ”¹è¿›å»ºè®®ï¼Œæ›´æ–°æ„å›¾ç´¢å¼•
                        if rating >= 4 and len(correction.strip()) > 0 and rag_manager is not None:
                            try:
                                rag_manager.refresh_intent_index()
                                st.info("ğŸ”„ æ„å›¾ç´¢å¼•å·²æ›´æ–°")
                            except Exception as e:
                                st.warning(f"âš ï¸ æ›´æ–°æ„å›¾ç´¢å¼•æ—¶å‡ºé”™: {e}")
                        
                        st.rerun()  # åˆ·æ–°é¡µé¢ä»¥æ˜¾ç¤ºå·²æäº¤çŠ¶æ€

        except Exception as e:
            error_message = f"æŠ±æ­‰ï¼Œå›ç­”æ—¶é‡åˆ°äº†ä¸€ä¸ªé”™è¯¯ï¼š{str(e)}"
            st.error(error_message)
            st.session_state.messages.append({"role": "assistant", "content": error_message})
            # ç¡®ä¿å˜é‡å·²å®šä¹‰ï¼ˆä½¿ç”¨é»˜è®¤å€¼ï¼‰
            if not full_response:
                full_response = error_message
            
            # å³ä½¿å‡ºé”™ä¹Ÿæ˜¾ç¤ºè¯„ä¼°æŒ‡æ ‡ï¼ˆå¦‚æœæœ‰éƒ¨åˆ†æ•°æ®ï¼‰
            try:
                metrics = calculate_metrics(
                    answer=full_response,
                    src_nodes=src_nodes,
                    used_intent_space=used_intent_space,
                    intent_score=intent_score
                )
                with st.expander("ğŸ“Š è¯„ä¼°æŒ‡æ ‡", expanded=False):
                    st.caption("âš ï¸ ç”±äºå‘ç”Ÿé”™è¯¯ï¼Œéƒ¨åˆ†æŒ‡æ ‡å¯èƒ½ä¸å®Œæ•´")
                    if rag_enabled:
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("æ£€ç´¢æ–‡æ¡£æ•°", metrics.retrieval_count)
                        with col2:
                            st.metric("ç½®ä¿¡åº¦", f"{metrics.confidence:.3f}")
                        with col3:
                            st.metric("ç²¾ç¡®ç‡", f"{metrics.precision:.3f}")
                        with col4:
                            st.metric("å¬å›ç‡", f"{metrics.recall:.3f}")
                    else:
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric("å›ç­”é•¿åº¦", f"{metrics.answer_length} å­—ç¬¦")
                        with col2:
                            st.metric("ç½®ä¿¡åº¦", f"{metrics.confidence:.3f}" if metrics.confidence > 0 else "N/A")
            except Exception as eval_error:
                logging.warning(f"è®¡ç®—è¯„ä¼°æŒ‡æ ‡å¤±è´¥: {eval_error}")
